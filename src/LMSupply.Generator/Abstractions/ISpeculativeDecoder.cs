using LMSupply.Generator.Models;

namespace LMSupply.Generator.Abstractions;

/// <summary>
/// Interface for speculative decoding which uses a smaller draft model
/// to generate candidate tokens that are verified by a larger target model.
/// This can significantly improve inference speed while maintaining quality.
/// </summary>
/// <remarks>
/// Speculative decoding works by:
/// 1. Draft model generates K candidate tokens quickly
/// 2. Target model verifies all K tokens in parallel
/// 3. Accepted tokens are kept, rejected tokens trigger regeneration
///
/// Typical speedup: 2-3x with appropriate draft/target model pairing.
/// </remarks>
public interface ISpeculativeDecoder : IAsyncDisposable
{
    /// <summary>
    /// Gets the draft model identifier.
    /// </summary>
    string DraftModelId { get; }

    /// <summary>
    /// Gets the target model identifier.
    /// </summary>
    string TargetModelId { get; }

    /// <summary>
    /// Gets or sets the number of tokens to speculate ahead.
    /// Higher values increase throughput but may decrease acceptance rate.
    /// Defaults to 5.
    /// </summary>
    int SpeculationLength { get; set; }

    /// <summary>
    /// Generates text using speculative decoding.
    /// </summary>
    /// <param name="prompt">The input prompt.</param>
    /// <param name="options">Generation options.</param>
    /// <param name="cancellationToken">Cancellation token.</param>
    /// <returns>Asynchronous stream of generated tokens.</returns>
    IAsyncEnumerable<SpeculativeToken> GenerateAsync(
        string prompt,
        GenerationOptions? options = null,
        CancellationToken cancellationToken = default);

    /// <summary>
    /// Generates complete text using speculative decoding.
    /// </summary>
    /// <param name="prompt">The input prompt.</param>
    /// <param name="options">Generation options.</param>
    /// <param name="cancellationToken">Cancellation token.</param>
    /// <returns>The complete generated text and statistics.</returns>
    Task<SpeculativeResult> GenerateCompleteAsync(
        string prompt,
        GenerationOptions? options = null,
        CancellationToken cancellationToken = default);

    /// <summary>
    /// Gets statistics from the last generation.
    /// </summary>
    SpeculativeStats GetLastStats();
}

/// <summary>
/// A token generated through speculative decoding with metadata.
/// </summary>
/// <param name="Token">The decoded token string.</param>
/// <param name="WasSpeculated">Whether this token came from the draft model.</param>
/// <param name="WasAccepted">Whether the speculation was accepted by the target model.</param>
public sealed record SpeculativeToken(
    string Token,
    bool WasSpeculated,
    bool WasAccepted);

/// <summary>
/// Result from speculative decoding generation.
/// </summary>
/// <param name="Text">The generated text.</param>
/// <param name="Stats">Statistics about the generation.</param>
public sealed record SpeculativeResult(
    string Text,
    SpeculativeStats Stats);

/// <summary>
/// Statistics from speculative decoding.
/// </summary>
public sealed record SpeculativeStats
{
    /// <summary>
    /// Total tokens generated.
    /// </summary>
    public required int TotalTokens { get; init; }

    /// <summary>
    /// Tokens generated by draft model.
    /// </summary>
    public required int DraftTokens { get; init; }

    /// <summary>
    /// Tokens accepted from draft model.
    /// </summary>
    public required int AcceptedTokens { get; init; }

    /// <summary>
    /// Tokens generated by target model (due to rejection or final verification).
    /// </summary>
    public required int TargetTokens { get; init; }

    /// <summary>
    /// Acceptance rate (AcceptedTokens / DraftTokens).
    /// </summary>
    public double AcceptanceRate =>
        DraftTokens > 0 ? (double)AcceptedTokens / DraftTokens : 0;

    /// <summary>
    /// Total generation time in milliseconds.
    /// </summary>
    public required long ElapsedMilliseconds { get; init; }

    /// <summary>
    /// Tokens per second throughput.
    /// </summary>
    public double TokensPerSecond =>
        ElapsedMilliseconds > 0 ? TotalTokens / (ElapsedMilliseconds / 1000.0) : 0;

    /// <summary>
    /// Gets a summary of the statistics.
    /// </summary>
    public string GetSummary() => $"""
        Total Tokens: {TotalTokens}
        Draft/Accepted: {DraftTokens}/{AcceptedTokens} ({AcceptanceRate:P1})
        Target Tokens: {TargetTokens}
        Throughput: {TokensPerSecond:F1} tok/s
        Time: {ElapsedMilliseconds}ms
        """;
}

/// <summary>
/// Options for speculative decoding.
/// </summary>
public sealed class SpeculativeDecodingOptions
{
    /// <summary>
    /// Number of tokens to speculate ahead.
    /// </summary>
    public int SpeculationLength { get; set; } = 5;

    /// <summary>
    /// Minimum acceptance rate before adjusting speculation length.
    /// </summary>
    public double MinAcceptanceRate { get; set; } = 0.5;

    /// <summary>
    /// Whether to dynamically adjust speculation length based on acceptance rate.
    /// </summary>
    public bool AdaptiveSpeculation { get; set; } = true;

    /// <summary>
    /// Temperature for draft model (typically lower than target).
    /// </summary>
    public float? DraftTemperature { get; set; }
}
